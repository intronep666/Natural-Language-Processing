{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2b5acada",
      "metadata": {
        "id": "2b5acada"
      },
      "source": [
        "\n",
        "# **Topic:** To implement text processing with a Neural Network (LSTM)\n",
        "\n",
        "**Name:** Prexit Joshi  \n",
        "**Roll No.:** UE233118\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5c273bd",
      "metadata": {
        "id": "c5c273bd"
      },
      "source": [
        "## Aim\n",
        "Implementation of text preprocessing and an LSTM model for basic sentiment classification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c7eab1",
      "metadata": {
        "id": "18c7eab1"
      },
      "source": [
        "## Description\n",
        "We will:\n",
        "- Use a very small sample dataset\n",
        "- Preprocess text (lowercase, simple cleaning)\n",
        "- Tokenize and pad sequences\n",
        "- Build a small LSTM model\n",
        "- Train and test and make one prediction\n",
        "\n",
        "Run cells one-by-one ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad45b742",
      "metadata": {
        "id": "ad45b742"
      },
      "source": [
        "## Requirements\n",
        "Google Colab has required libraries. If running locally:\n",
        "```\n",
        "pip install tensorflow pandas scikit-learn\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b3e6d0c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3e6d0c6",
        "outputId": "e5a9395b-09b8-4878-a456-9ac6fb36083d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# 1) Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "print('TF version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e8fe73e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8fe73e0",
        "outputId": "c63fb09d-c8e3-4a22-9792-23453fc5ba23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     text     label\n",
            "0             I love this  positive\n",
            "1             I hate this  negative\n",
            "2         This is awesome  positive\n",
            "3             This is bad  negative\n",
            "4  Really good experience  positive\n",
            "5   Really bad experience  negative\n"
          ]
        }
      ],
      "source": [
        "# 2) Very small dataset (easy to understand)\n",
        "data = {\n",
        "    'text': [\n",
        "        'I love this',\n",
        "        'I hate this',\n",
        "        'This is awesome',\n",
        "        'This is bad',\n",
        "        'Really good experience',\n",
        "        'Really bad experience'\n",
        "    ],\n",
        "    'label': ['positive','negative','positive','negative','positive','negative']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cc75cc28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc75cc28",
        "outputId": "65937972-fab5-4952-a43b-040d7e316873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 4 Test: 2\n",
            "\n",
            "Train samples:\n",
            " ['Really good experience' 'I love this' 'This is bad'\n",
            " 'Really bad experience']\n"
          ]
        }
      ],
      "source": [
        "# 3) Encode labels and split\n",
        "e = LabelEncoder()\n",
        "df['label_enc'] = e.fit_transform(df['label'])\n",
        "X = df['text']\n",
        "y = df['label_enc']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "print('Train:', len(X_train), 'Test:', len(X_test))\n",
        "print('\\nTrain samples:\\n', X_train.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bcb008bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcb008bc",
        "outputId": "67198748-8bd9-4d93-ed65-c8e04cc8e3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example: Really good experience -> [2, 6, 3] -> [2 6 3 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# 4) Tokenize & pad\n",
        "vocab_size = 50\n",
        "max_len = 6\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "print('Example:', X_train.values[0], '->', X_train_seq[0], '->', X_train_pad[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c20ff7bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "c20ff7bf",
        "outputId": "1a375693-ea83-4ca9-e973-10699993d2dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 5) Build a tiny LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=8, input_length=max_len),\n",
        "    LSTM(8),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3df4c3a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3df4c3a8",
        "outputId": "0625421f-dc44-46d9-de92-ee51b401562a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.5000 - loss: 0.6941 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 2/8\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5000 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 3/8\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.6667 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
            "Epoch 4/8\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.5000 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 5/8\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.5000 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
            "Epoch 6/8\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.5000 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 7/8\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6667 - loss: 0.6931 - val_accuracy: 0.0000e+00 - val_loss: 0.6943\n",
            "Epoch 8/8\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.8333 - loss: 0.6916 - val_accuracy: 0.0000e+00 - val_loss: 0.6945\n"
          ]
        }
      ],
      "source": [
        "# 6) Train (very few epochs to keep it simple)\n",
        "history = model.fit(X_train_pad, y_train, epochs=8, batch_size=2, validation_data=(X_test_pad, y_test), verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ed23a033",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed23a033",
        "outputId": "c55d5578-bd3b-4a28-fb4d-38ed3eb0591e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc: 0.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Text: I really love this product\n",
            "Prob positive: 0.499\n",
            "Predicted label: negative\n"
          ]
        }
      ],
      "source": [
        "# 7) Evaluate and predict\n",
        "loss, acc = model.evaluate(X_test_pad, y_test, verbose=0)\n",
        "print(f'Test acc: {acc:.2f}')\n",
        "\n",
        "# Single sample prediction\n",
        "sample = ['I really love this product']\n",
        "seq = tokenizer.texts_to_sequences(sample)\n",
        "pad = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "prob = model.predict(pad)[0][0]\n",
        "print('Text:', sample[0])\n",
        "print('Prob positive:', round(float(prob),3))\n",
        "print('Predicted label:', 'positive' if prob>0.5 else 'negative')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9f1554",
      "metadata": {
        "id": "cc9f1554"
      },
      "source": [
        "## Conclusion\n",
        "This practical demonstrated a simple text-processing workflow using an LSTM-based neural network for sentiment classification. We converted text into padded sequences, trained a basic LSTM model, and evaluated its performance on test data. The experiment shows how LSTM networks can learn patterns from sequential text and can be applied effectively to basic NLP tasks. The objective of implementing text processing with a neural network was successfully achieved."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}