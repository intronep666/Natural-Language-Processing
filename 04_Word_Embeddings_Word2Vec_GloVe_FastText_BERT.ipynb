{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ***NLP Practical: Word Embeddings (Word2Vec, GloVe, FastText, BERT)***\n",
        "\n",
        "***Name: Prexit Joshi***\n",
        "\n",
        " ***Roll No.: 118***\n",
        "\n"
      ],
      "metadata": {
        "id": "CTlYQlAu3hkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates how to implement and use various word embedding techniques to represent text as numerical vectors. We will explore:\n",
        "\n",
        "Word2Vec\n",
        "\n",
        "GloVe\n",
        "\n",
        "FastText\n",
        "\n",
        "BERT\n",
        "\n",
        "Word embeddings are a cornerstone of modern NLP, as they capture the semantic meaning and relationships between words. We will use Python's gensim and transformers libraries to implement these techniques."
      ],
      "metadata": {
        "id": "KGDMyiQa7RCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q gensim transformers torch\n",
        "\n",
        "# Import libraries\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Example corpus, tokenized and lowercased\n",
        "corpus = [\n",
        "    \"Natural Language Processing is a part of Artificial Intelligence\",\n",
        "    \"TF and TF-IDF are important techniques for feature extraction\",\n",
        "    \"Feature extraction helps in text mining and information retrieval\",\n",
        "    \"TF-IDF reduces the weight of common words in the corpus\"\n",
        "]\n",
        "tokenized_corpus = [doc.lower().split() for doc in corpus]"
      ],
      "metadata": {
        "id": "uPfgsrqn7hyx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Word2Vec***\n",
        "\n",
        "Word2Vec is a predictive model that learns word vectors by predicting a word from its context. It captures semantic relationships well but cannot create vectors for out-of-vocabulary (OOV) words."
      ],
      "metadata": {
        "id": "ad1FThpp8SXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Word2Vec (Skip-gram) model\n",
        "word2vec_model = gensim.models.Word2Vec(sentences=tokenized_corpus, vector_size=50, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Get vector for a word\n",
        "print(\"Word2Vec vector for 'feature':\\n\", word2vec_model.wv['feature'][:5])\n",
        "\n",
        "# Find similar words\n",
        "print(\"\\nWords similar to 'extraction':\\n\", word2vec_model.wv.most_similar('extraction', topn=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LuwNMOMbBlNa",
        "outputId": "23767f75-4c1c-4eff-de6f-89641a3614a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec vector for 'feature':\n",
            " [-0.01724207  0.00733798  0.0103818   0.0115101   0.01493315]\n",
            "\n",
            "Words similar to 'extraction':\n",
            " [('mining', 0.23062904179096222), ('language', 0.22057761251926422)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. GloVe***\n",
        "\n",
        "GloVe (Global Vectors) is a count-based model that learns vectors from a global word-word co-occurrence matrix. We typically use pre-trained models."
      ],
      "metadata": {
        "id": "C0W22Vh_Dh95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained GloVe model\n",
        "glove_model = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "# Get vector for a word\n",
        "print(\"GloVe vector for 'computer':\\n\", glove_model['computer'][:5])\n",
        "\n",
        "# Find similar words\n",
        "print(\"\\nWords similar to 'nlp':\\n\", glove_model.most_similar('nlp', topn=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RmZdAipuDjJZ",
        "outputId": "0fc1cbeb-7195-4342-be20-c15e1993f17b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GloVe vector for 'computer':\n",
            " [ 0.079084 -0.81504   1.7901    0.91653   0.10797 ]\n",
            "\n",
            "Words similar to 'nlp':\n",
            " [('hagelin', 0.7022942304611206), ('.760', 0.6916053891181946)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***3. FastText***\n",
        "\n",
        "FastText extends Word2Vec by treating words as a bag of character n-grams. This allows it to generate vectors for out-of-vocabulary (OOV) words."
      ],
      "metadata": {
        "id": "46hWezW8EDmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a FastText model\n",
        "fasttext_model = gensim.models.FastText(sentences=tokenized_corpus, vector_size=50, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Get vector for an OOV word ('extractions' is not in the corpus)\n",
        "print(\"FastText vector for OOV word 'extractions':\\n\", fasttext_model.wv['extractions'][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7nCTH3RSEK-S",
        "outputId": "75305ca2-2ad2-4deb-eedf-f23f000e1811"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText vector for OOV word 'extractions':\n",
            " [-3.3362366e-03 -1.6197474e-03  9.3988667e-05  2.1759269e-04\n",
            " -1.3983970e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. BERT***\n",
        "\n",
        "BERT is a transformer-based model that generates contextual embeddings. The vector for a word changes based on its surrounding sentence, allowing it to capture context and nuance."
      ],
      "metadata": {
        "id": "bPkcHHcIETx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Sentences with the same word in different contexts\n",
        "sentence1 = \"Feature extraction is a technique.\"\n",
        "sentence2 = \"This car has a new safety feature.\"\n",
        "\n",
        "# Get contextual embedding for 'feature' in sentence 1\n",
        "inputs1 = tokenizer(sentence1, return_tensors='pt')\n",
        "outputs1 = model(**inputs1)\n",
        "feature_vector1 = outputs1.last_hidden_state[0, 1, :] # 'feature' is the 2nd token\n",
        "\n",
        "# Get contextual embedding for 'feature' in sentence 2\n",
        "inputs2 = tokenizer(sentence2, return_tensors='pt')\n",
        "outputs2 = model(**inputs2)\n",
        "feature_vector2 = outputs2.last_hidden_state[0, 6, :] # 'feature' is the 7th token\n",
        "\n",
        "# Check if vectors are different\n",
        "similarity = torch.nn.functional.cosine_similarity(feature_vector1, feature_vector2, dim=0)\n",
        "print(f\"Similarity between the two 'feature' vectors: {similarity.item():.4f}\")\n",
        "print(\"(A value less than 1.0 proves they are different)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GpU_J0GQEYQa",
        "outputId": "28eb2964-5ed8-41bb-ba4d-0bac1aa7ff58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between the two 'feature' vectors: 0.2005\n",
            "(A value less than 1.0 proves they are different)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Conclusion***\n",
        "\n",
        "Word2Vec, GloVe, and FastText produce static embeddings (one vector per word), with FastText's key advantage being its ability to handle OOV words. In contrast, BERT provides dynamic, contextual embeddings that understand a word's meaning in a specific sentence, offering superior performance for complex NLP tasks."
      ],
      "metadata": {
        "id": "SNjxCguqEjC1"
      }
    }
  ]
}