{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e9f51664",
      "metadata": {
        "id": "e9f51664"
      },
      "source": [
        "# ***To Implement text processing with LSTM***\n",
        "\n",
        "\n",
        "**Name:** Prexit Joshi  \n",
        "**Roll No.:** 118\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c872557f",
      "metadata": {
        "id": "c872557f"
      },
      "source": [
        "## 1. Aim\n",
        "To implement a basic text-processing pipeline and train a small LSTM model for sentiment classification using Keras (TensorFlow)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4128a9ae",
      "metadata": {
        "id": "4128a9ae"
      },
      "source": [
        "## 2. Description\n",
        "This practical demonstrates how raw text is preprocessed and converted to numerical inputs suitable for neural networks. Steps include:\n",
        "\n",
        "- Simple text cleaning (lowercasing)\n",
        "- Tokenization and converting words to integer sequences\n",
        "- Padding sequences to a fixed length\n",
        "- Building and training a small LSTM network\n",
        "- Evaluating model performance and making predictions\n",
        "\n",
        "The notebook uses a small sample dataset for clarity; the same pipeline applies to larger datasets with minimal changes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab0de3b9",
      "metadata": {
        "id": "ab0de3b9"
      },
      "source": [
        "## 3. Requirements\n",
        "- Google Colab (recommended) or local Jupyter\n",
        "- Libraries: `numpy`, `pandas`, `tensorflow`, `sklearn`\n",
        "\n",
        "If running locally, install with:\n",
        "```\n",
        "pip install numpy pandas tensorflow scikit-learn\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "69441d2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69441d2a",
        "outputId": "6ced04df-03a8-430b-d7e1-5493ce7b402a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# 4.1 Imports and seed\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Reproducibility (best-effort)\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print('TensorFlow version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8352e3ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8352e3ac",
        "outputId": "937b9020-cae7-47f0-bf10-a5c4f7508d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset preview:\n",
            "                             text     label\n",
            "1             I love this product  positive\n",
            "2               This is the worst  negative\n",
            "3    Absolutely fantastic service  positive\n",
            "4                       I hate it  negative\n",
            "5  Not satisfied with the quality  negative\n"
          ]
        }
      ],
      "source": [
        "# 4.2 Small sample dataset\n",
        "# Replace this with a real dataset (CSV) when required\n",
        "data = {\n",
        "    'text': [\n",
        "        'I love this product',\n",
        "        'This is the worst',\n",
        "        'Absolutely fantastic service',\n",
        "        'I hate it',\n",
        "        'Not satisfied with the quality',\n",
        "        'Very happy with my purchase',\n",
        "        'Will never buy again',\n",
        "        'Best experience ever',\n",
        "        'Terrible customer support',\n",
        "        'I really liked it'\n",
        "    ],\n",
        "    'label': ['positive','negative','positive','negative','negative','positive','negative','positive','negative','positive']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.index += 1  # lab-style indices\n",
        "print('Dataset preview:')\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fc2c1c76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc2c1c76",
        "outputId": "2060fb5c-262f-4f65-d2ab-8221ac0ab8e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 8 Test size: 2\n"
          ]
        }
      ],
      "source": [
        "# 4.3 Encode labels and split\n",
        "le = LabelEncoder()\n",
        "df['label_enc'] = le.fit_transform(df['label'])\n",
        "\n",
        "X = df['text']\n",
        "y = df['label_enc']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
        "print('Train size:', len(X_train), 'Test size:', len(X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "65cb4f45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65cb4f45",
        "outputId": "1d8123af-b658-4422-c709-b71ff72eacb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example:\n",
            "Text: best experience ever\n",
            "Sequence: [6, 7, 8]\n",
            "Padded: [6 7 8 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# 4.4 Simple preprocessing, tokenization, and padding\n",
        "# Lowercase (simple cleaning)\n",
        "X_train = X_train.str.lower()\n",
        "X_test = X_test.str.lower()\n",
        "\n",
        "VOCAB_SIZE = 500\n",
        "OOV_TOKEN = '<OOV>'\n",
        "MAX_LEN = 10\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOKEN)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "print('Example:')\n",
        "print('Text:', X_train.iloc[0])\n",
        "print('Sequence:', X_train_seq[0])\n",
        "print('Padded:', X_train_pad[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "52330d41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "52330d41",
        "outputId": "c6aec0ac-5ada-460d-da1e-928317e06b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 4.5 Build small LSTM model\n",
        "EMBED_DIM = 32\n",
        "LSTM_UNITS = 32\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=EMBED_DIM, input_length=MAX_LEN),\n",
        "    LSTM(LSTM_UNITS),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5977c40a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5977c40a",
        "outputId": "57cba8a9-5587-4443-ccef-67c8864451a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - accuracy: 0.2167 - loss: 0.6970 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 2/8\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6833 - loss: 0.6842 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
            "Epoch 3/8\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6833 - loss: 0.6823 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 4/8\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6833 - loss: 0.6751 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
            "Epoch 5/8\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5833 - loss: 0.6872 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 6/8\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6833 - loss: 0.6880 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 7/8\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5500 - loss: 0.6839 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 8/8\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4500 - loss: 0.6849 - val_accuracy: 0.5000 - val_loss: 0.6947\n"
          ]
        }
      ],
      "source": [
        "# 4.6 Train the model (small epochs for demo)\n",
        "EPOCHS = 8\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_test_pad, y_test),\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ff4b258f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff4b258f",
        "outputId": "9b36be0d-d3b9-40d4-ae1c-ddc6010ff010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6947, Test accuracy: 0.5000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "Text: I absolutely love this service\n",
            "Prob positive: 0.4936 -> Pred: negative\n",
            "\n",
            "Text: Worst product I bought\n",
            "Prob positive: 0.4893 -> Pred: negative\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4.7 Evaluate and sample prediction\n",
        "loss, acc = model.evaluate(X_test_pad, y_test, verbose=0)\n",
        "print(f'Test loss: {loss:.4f}, Test accuracy: {acc:.4f}')\n",
        "\n",
        "# Helper to predict\n",
        "def predict_text(text_list):\n",
        "    texts = [t.lower() for t in text_list]\n",
        "    seq = tokenizer.texts_to_sequences(texts)\n",
        "    pad = pad_sequences(seq, maxlen=MAX_LEN, padding='post')\n",
        "    probs = model.predict(pad)\n",
        "    labels = le.inverse_transform([0,1]) if False else ['negative','positive']\n",
        "    for t,p in zip(text_list, probs):\n",
        "        print(f\"Text: {t}\\nProb positive: {p[0]:.4f} -> Pred: {labels[int(p[0]>0.5)]}\\n\")\n",
        "\n",
        "predict_text(['I absolutely love this service', 'Worst product I bought'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "690eaf33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "690eaf33",
        "outputId": "191101dc-01ba-4473-d74b-38aec7d636df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /mnt/data/text_lstm_model.h5\n"
          ]
        }
      ],
      "source": [
        "# 4.8 Save model (optional)\n",
        "model_path = '/mnt/data/text_lstm_model.h5'\n",
        "model.save(model_path)\n",
        "print('Model saved to', model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b4dc1c",
      "metadata": {
        "id": "88b4dc1c"
      },
      "source": [
        "## 5. Observations\n",
        "- Tokenization converts words to integer IDs; padding makes sequences equal length for batch processing.\n",
        "- LSTM captures sequence information (word order) which helps in tasks like sentiment classification.\n",
        "- On very small datasets the model may overfit; for reliable results use larger datasets and regularization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e366fe8d",
      "metadata": {
        "id": "e366fe8d"
      },
      "source": [
        "## 6. Conclusion\n",
        "\n",
        "This practical implemented a basic text-processing pipeline and trained a small LSTM-based neural network for binary sentiment classification. Raw sentences were lowercased, tokenized, and padded before being fed into an embedding layer and LSTM. The experiment demonstrates the end-to-end process for preparing textual data and using sequence models to learn patterns. Although a small dataset was used here for instructional purposes, the same pipeline is applicable to larger datasets with further tuning and validation.\n",
        "\n",
        "---\n",
        "\n",
        "**Prepared by:** Prexit Joshi  \n",
        "**Roll No.:** 118"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}